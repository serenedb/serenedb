query
SHOW ALL;
----
name	value	description
execution_threads	0	Sets the number of threads used for query execution. If set to 0, serial execution (execution in connection thread) is used. Otherwise the execution is separated from connection thread and desired number of threads will be tried to be used.
join_order_algorithm	cost	Sets the join algorithm to be used for query execution. Valid values are 'cost' (the default), 'greedy', and 'syntactic'.
search_path	"$user", public	Sets the schema search order for names that are not schema-qualified.
extra_float_digits	1	Sets the number of digits displayed for floating-point values.
bytea_output	hex	Sets the output format for values of type bytea. Valid values are 'hex' (the default) and 'escape' (the traditional PostgreSQL format).
client_encoding	UTF8	Sets the client character set encoding.
datestyle	ISO, MDY	Sets the display format for date and time values.
application_name	(empty)	Sets the application name to be reported in statistics and logs.
default_transaction_read_only	off	Sets the default read-only status of new transactions.
in_hot_standby	off	Shows whether the server is currently in hot standby mode.
integer_datetimes	on	Shows whether datetimes are integer based.
intervalstyle	postgres	Sets the display format for interval values.
scram_iterations	4096	Sets the number of SCRAM iterations for password hashing.
server_encoding	UTF8	Sets the server character set encoding.
server_version	18.1	Shows the server version.
standard_conforming_strings	on	Causes '...' strings to treat backslashes literally.
timezone	Etc/UTC	Sets the time zone for displaying and interpreting time stamps.
query_max_memory_per_node	0B	Maximum memory that a query can use on a single host.
session_timezone	(empty)	User provided session timezone. Stores a string with the actual timezone name, e.g: "America/Los_Angeles".
adjust_timestamp_to_session_timezone	false	If true, timezone-less timestamp conversions (e.g. string to timestamp, when the string does not specify a timezone) will be adjusted to the user provided session timezone (if any). False by default.
expression.eval_simplified	false	Whether to use the simplified expression evaluation path. False by default.
expression.track_cpu_usage	false	Whether to track CPU usage for individual expressions (supported by call and cast expressions). False by default. Can be expensive when processing small batches, e.g. < 10K rows.
track_operator_cpu_usage	true	Whether to track CPU usage for stages of individual operators. True by default. Can be expensive when processing small batches, e.g. < 10K rows.
legacy_cast	false	Flags used to configure the CAST operator
cast_match_struct_by_name	false	This flag makes the Row conversion to by applied in a way that the casting row field are matched by name instead of position.
expression.max_array_size_in_reduce	100000	Reduce() function will throw an error if encountered an array of size greater than this.
expression.max_compiled_regexes	100	Controls maximum number of compiled regular expression patterns per function instance per thread of execution.
max_local_exchange_buffer_size	33554432	Used for backpressure to block local exchange producers when the local exchange buffer reaches or exceeds this size.
max_local_exchange_partition_count	4294967295	Limits the number of partitions created by a local exchange. Partitioning data too granularly can lead to poor performance. This setting allows increasing the task concurrency for all pipelines except the ones that require a local partitioning. Affects the number of drivers for pipelines containing LocalPartitionNode and cannot exceed the maximum number of pipeline drivers configured for the task.
min_local_exchange_partition_count_to_use_partition_buffer	33	Minimum number of local exchange output partitions to use buffered partitioning.
max_local_exchange_partition_buffer_size	65536	Maximum size in bytes to accumulate for a single partition of a local exchange before flushing.
local_exchange_partition_buffer_preserve_encoding	false	Try to preserve the encoding of the input vector when copying it to the buffer.
local_merge_source_queue_size	2	Maximum number of vectors buffered in each local merge source before blocking to wait for consumers.
exchange.max_buffer_size	33554432	Maximum size in bytes to accumulate in ExchangeQueue. Enforced approximately, not strictly.
merge_exchange.max_buffer_size	134217728	Maximum size in bytes to accumulate among all sources of the merge exchange. Enforced approximately, not strictly.
min_exchange_output_batch_bytes	2097152	The minimum number of bytes to accumulate in the ExchangeQueue before unblocking a consumer. This is used to avoid creating tiny batches which may have a negative impact on performance when the cost of creating vectors is high (for example, when there are many columns). To avoid latency degradation, the exchange client unblocks a consumer when 1% of the data size observed so far is accumulated.
max_partial_aggregation_memory	16777216	(empty)
max_extended_partial_aggregation_memory	67108864	(empty)
abandon_partial_aggregation_min_rows	100000	(empty)
abandon_partial_aggregation_min_pct	80	(empty)
abandon_partial_topn_row_number_min_rows	100000	(empty)
abandon_partial_topn_row_number_min_pct	80	(empty)
max_elements_size_in_repeat_and_sequence	10000	(empty)
max_page_partitioning_buffer_size	33554432	The maximum number of bytes to buffer in PartitionedOutput operator to avoid creating tiny SerializedPages.
max_output_buffer_size	33554432	The maximum size in bytes for the task's buffered output. The producer Drivers are blocked when the buffered size exceeds this. The Drivers are resumed when the buffered size goes below OutputBufferManager::kContinuePct % of this.
preferred_output_batch_bytes	10485760	Preferred size of batches in bytes to be returned by operators from Operator::getOutput. It is used when an estimate of average row size is known. Otherwise kPreferredOutputBatchRows is used.
preferred_output_batch_rows	1024	Preferred number of rows to be returned by operators from Operator::getOutput. It is used when an estimate of average row size is not known. When the estimate of average row size is known, kPreferredOutputBatchBytes is used.
max_output_batch_rows	10000	Max number of rows that could be return by operators from Operator::getOutput. It is used when an estimate of average row size is known and kPreferredOutputBatchBytes is used to compute the number of output rows.
table_scan_getoutput_time_limit_ms	5000	TableScan operator will exit getOutput() method after this many milliseconds even if it has no data to return yet. Zero means 'no time limit'.
hash_adaptivity_enabled	true	If false, the 'group by' code is forced to use generic hash mode hashtable.
adaptive_filter_reordering_enabled	true	If true, the conjunction expression can reorder inputs based on the time taken to calculate them.
spill_enabled	false	Global enable spilling flag.
aggregation_spill_enabled	true	Aggregation spilling flag, only applies if "spill_enabled" flag is set.
join_spill_enabled	true	Join spilling flag, only applies if "spill_enabled" flag is set.
mixed_grouped_mode_hash_join_spill_enabled	false	Config to enable hash join spill for mixed grouped execution mode.
order_by_spill_enabled	true	OrderBy spilling flag, only applies if "spill_enabled" flag is set.
window_spill_enabled	true	Window spilling flag, only applies if "spill_enabled" flag is set.
writer_spill_enabled	true	If true, the memory arbitrator will reclaim memory from table writer by flushing its buffered data to disk. only applies if "spill_enabled" flag is set.
row_number_spill_enabled	true	RowNumber spilling flag, only applies if "spill_enabled" flag is set.
topn_row_number_spill_enabled	true	TopNRowNumber spilling flag, only applies if "spill_enabled" flag is set.
local_merge_spill_enabled	false	LocalMerge spilling flag, only applies if "spill_enabled" flag is set.
local_merge_max_num_merge_sources	4294967295	Specify the max number of local sources to merge at a time.
max_spill_run_rows	12582912	The max row numbers to fill and spill for each spill run. This is used to cap the memory used for spilling. If it is zero, then there is no limit and spilling might run out of memory. Based on offline test results, the default value is set to 12 million rows which uses ~128MB memory when to fill a spill run.
max_spill_bytes	107374182400	The max spill bytes limit set for each query. This is used to cap the storage used for spilling. If it is zero, then there is no limit and spilling might exhaust the storage or takes too long to run. The default value is set to 100 GB.
max_spill_level	1	The max allowed spilling level with zero being the initial spilling level. This only applies for hash build spilling which might trigger recursive spilling when the build table is too big. If it is set to -1, then there is no limit and then some extreme large query might run out of spilling partition bits (see kSpillPartitionBits) at the end. The max spill level is used in production to prevent some bad user queries from using too much io and cpu resources.
max_spill_file_size	0	The max allowed spill file size. If it is zero, then there is no limit.
spill_compression_codec	none	(empty)
spill_prefixsort_enabled	false	Enable the prefix sort or fallback to timsort in spill. The prefix sort is faster than std::sort but requires the memory to build normalized prefix keys, which might have potential risk of running out of server memory.
spill_write_buffer_size	1048576	Specifies spill write buffer size in bytes. The spiller tries to buffer serialized spill data up to the specified size before write to storage underneath for io efficiency. If it is set to zero, then spill write buffering is disabled.
spill_read_buffer_size	1048576	Specifies the buffer size in bytes to read from one spilled file. If the underlying filesystem supports async read, we do read-ahead with double buffering, which doubles the buffer used to read from each spill file.
spill_file_create_config	(empty)	Config used to create spill files. This config is provided to underlying file system and the config is free form. The form should be defined by the underlying file system.
spiller_start_partition_bit	48	Default offset spill start partition bit. It is used with 'kSpillNumPartitionBits' together to calculate the spilling partition number for join spill or aggregation spill.
spiller_num_partition_bits	3	Default number of spill partition bits. It is the number of bits used to calculate the spill partition number for hash join and RowNumber. The number of spill partitions will be power of two. NOTE: as for now, we only support up to 8-way spill partitioning.
min_spillable_reservation_pct	5	The minimal available spillable memory reservation in percentage of the current memory usage. Suppose the current memory usage size of M, available memory reservation size of N and min reservation percentage of P, if M * P / 100 > N, then spiller operator needs to grow the memory reservation with percentage of spillableReservationGrowthPct(). This ensures we have sufficient amount of memory reservation to process the large input outlier.
spillable_reservation_growth_pct	10	The spillable memory reservation growth percentage of the previous memory reservation size. 10 means exponential growth along a series of integer powers of 11/10. The reservation grows by this much until it no longer can, after which it starts spilling.
writer_flush_threshold_bytes	100663296	Minimum memory footprint size required to reclaim memory from a file writer by flushing its buffered data to disk.
presto.array_agg.ignore_nulls	false	If true, array_agg() aggregation function will ignore nulls in the input.
spark.ansi_enabled	false	If true, Spark function's behavior is ANSI-compliant, e.g. throws runtime exception instead of returning null on invalid inputs. Note: This feature is still under development to achieve full ANSI compliance. Users can refer to the Spark function documentation to verify the current support status of a specific function.
spark.bloom_filter.expected_num_items	1000000	The default number of expected items for the bloomfilter.
spark.bloom_filter.num_bits	8388608	The default number of bits to use for the bloom filter.
spark.bloom_filter.max_num_bits	4194304	The max number of bits to use for the bloom filter.
spark.partition_id	(empty)	The current spark partition id.
spark.legacy_date_formatter	false	If true, simple date formatter is used for time formatting and parsing. Joda date formatter is used by default.
spark.legacy_statistical_aggregate	false	If true, Spark statistical aggregation functions including skewness, kurtosis, stddev, stddev_samp, variance, var_samp, covar_samp and corr will return NaN instead of NULL when dividing by zero during expression evaluation.
spark.json_ignore_null_fields	true	If true, ignore null fields when generating JSON string. If false, null fields are included with a null value.
task_writer_count	4	The number of local parallel table writer operators per task.
task_partitioned_writer_count	4	The number of local parallel table writer operators per task for partitioned writes. If not set, use "task_writer_count".
hash_probe_finish_early_on_empty_build	false	If true, finish the hash probe on an empty build table for a specific set of hash joins.
min_table_rows_for_parallel_join_build	1000	The minimum number of table rows that can trigger the parallel hash join table build.
debug.validate_output_from_operators	false	If set to true, then during execution of tasks, the output vectors of every operator are validated for consistency. This is an expensive check so should only be used for debugging. It can help debug issues where malformed vector cause failures or crashes by helping identify which operator is generating them.
enable_expression_evaluation_cache	true	If true, enable caches in expression evaluation for performance, including ExecCtx::vectorPool_, ExecCtx::decodedVectorPool_, ExecCtx::selectivityVectorPool_, Expr::baseDictionary_, Expr::dictionaryCache_, and Expr::cachedDictionaryIndices_. Otherwise, disable the caches.
max_shared_subexpr_results_cached	10	For a given shared subexpression, the maximum distinct sets of inputs we cache results for. Lambdas can call the same expression with different inputs many times, causing the results we cache to explode in size. Putting a limit contains the memory usage.
max_split_preload_per_driver	2	Maximum number of splits to preload. Set to 0 to disable preloading.
driver_cpu_time_slice_limit_ms	0	If not zero, specifies the cpu time slice limit in ms that a driver thread can continuously run without yielding. If it is zero, then there is no limit.
prefixsort_normalized_key_max_bytes	128	Maximum number of bytes to use for the normalized key in prefix-sort. Use 0 to disable prefix-sort.
prefixsort_min_rows	128	Minimum number of rows to use prefix-sort. The default value has been derived using micro-benchmarking.
prefixsort_max_string_prefix_length	16	Maximum number of bytes to be stored in prefix-sort buffer for a string key.
query_trace_enabled	false	Enable query tracing flag.
query_trace_dir	(empty)	Base dir of a query to store tracing data.
query_trace_node_id	(empty)	The plan node id whose input data will be traced. Empty string if only want to trace the query metadata.
query_trace_max_bytes	0	The max trace bytes limit. Tracing is disabled if zero.
query_trace_task_reg_exp	(empty)	The regexp of traced task id. We only enable trace on a task if its id matches.
query_trace_dry_run	false	If true, we only collect the input trace for a given operator but without the actual execution.
op_trace_directory_create_config	(empty)	Config used to create operator trace directory. This config is provided to underlying file system and the config is free form. The form should be defined by the underlying file system.
debug_disable_expression_with_peeling	false	Disable optimization in expression evaluation to peel common dictionary layer from inputs.
debug_disable_common_sub_expressions	false	Disable optimization in expression evaluation to re-use cached results for common sub-expressions.
debug_disable_expression_with_memoization	false	Disable optimization in expression evaluation to re-use cached results between subsequent input batches that are dictionary encoded and have the same alphabet(underlying flat vector).
debug_disable_expression_with_lazy_inputs	false	Disable optimization in expression evaluation to delay loading of lazy inputs unless required.
debug_aggregation_approx_percentile_fixed_random_seed	(empty)	Fix the random seed used to create data structure used in approx_percentile. This makes the query result deterministic on single node; multi-node partial aggregation is still subject to non-determinism due to non-deterministic merge order.
debug_memory_pool_name_regex	(empty)	When debug is enabled for memory manager, this is used to match the memory pools that need allocation callsites tracking. Default to track nothing.
debug_memory_pool_warn_threshold_bytes	0	Warning threshold in bytes for debug memory pools. When set to a non-zero value, a warning will be logged once per memory pool when allocations cause the pool to exceed this threshold. This is useful for identifying memory usage patterns during debugging. Requires allocation tracking to be enabled via `debug_memory_pool_name_regex` for the pool. A value of 0 means no warning threshold is enforced.
debug_lambda_function_evaluation_batch_size	10000	Some lambda functions over arrays and maps are evaluated in batches of the underlying elements that comprise the arrays/maps. This is done to make the batch size manageable as array vectors can have thousands of elements each and hit scaling limits as implementations typically expect BaseVectors to a couple of thousand entries. This lets up tune those batch sizes.
debug_bing_tile_children_max_zoom_shift	5	The UDF `bing_tile_children` generates the children of a Bing tile based on a specified target zoom level. The number of children produced is determined by the difference between the target zoom level and the zoom level of the input tile. This configuration limits the number of children by capping the maximum zoom level difference, with a default value set to 5. This cap is necessary to prevent excessively large array outputs, which can exceed the size limits of the elements vector in the Velox array vector.
selective_nimble_reader_enabled	false	Temporary flag to control whether selective Nimble reader should be used in this query or not. Will be removed after the selective Nimble reader is fully rolled out.
scaled_writer_rebalance_max_memory_usage_ratio	0.7	The max ratio of a query used memory to its max capacity, and the scale writer exchange stops scaling writer processing if the query's current memory usage exceeds this ratio. The value is in the range of (0, 1].
scaled_writer_max_partitions_per_writer	128	The max number of logical table partitions that can be assigned to a single table writer thread. The logical table partition is used by local exchange writer for writer scaling, and multiple physical table partitions can be mapped to the same logical table partition based on the hash value of calculated partitioned ids.
scaled_writer_min_partition_processed_bytes_rebalance_threshold	134217728	Minimum amount of data processed by a logical table partition to trigger writer scaling if it is detected as overloaded by scale wrirer exchange.
scaled_writer_min_processed_bytes_rebalance_threshold	268435456	Minimum amount of data processed by all the logical table partitions to trigger skewed partition rebalancing by scale writer exchange.
table_scan_scaled_processing_enabled	false	If true, enables the scaled table scan processing. For each table scan plan node, a scan controller is used to control the number of running scan threads based on the query memory usage. It keeps increasing the number of running threads until the query memory usage exceeds the threshold defined by 'table_scan_scale_up_memory_usage_ratio'.
table_scan_scale_up_memory_usage_ratio	0.7	The query memory usage ratio used by scan controller to decide if it can increase the number of running scan threads. When the query memory usage is below this ratio, the scan controller keeps increasing the running scan thread for scale up, and stop once exceeds this ratio. The value is in the range of [0, 1]. NOTE: this only applies if 'table_scan_scaled_processing_enabled' is true.
shuffle_compression_codec	none	Specifies the shuffle compression kind which is defined by CompressionKind. If it is CompressionKind_NONE, then no compression.
throw_exception_on_duplicate_map_keys	false	If a key is found in multiple given maps, by default that key's value in the resulting map comes from the last one of those maps. When true, throw exception on duplicate map key.
index_lookup_join_max_prefetch_batches	0	Specifies the max number of input batches to prefetch to do index lookup ahead. If it is zero, then process one input batch at a time.
index_lookup_join_split_output	true	If this is true, then the index join operator might split output for each input batch based on the output batch size control. Otherwise, it tries to produce a single output for each input batch.
request_data_sizes_max_wait_sec	10	Max wait time for exchange request in seconds.
streaming_aggregation_min_output_batch_rows	0	In streaming aggregation, wait until we have enough number of output rows to produce a batch of size specified by this. If set to 0, then Operator::outputBatchRows will be used as the min output batch rows.
streaming_aggregation_eager_flush	false	TODO: Remove after dependencies are cleaned up.
field_names_in_json_cast_enabled	false	If this is true, then it allows you to get the struct field names as json element names when casting a row to json.
operator_track_expression_stats	false	If this is true, then operators that evaluate expressions will track stats for expressions that are not special forms and return them as part of their operator stats. Tracking these stats can be expensive (especially if operator stats are retrieved frequently) and this allows the user to explicitly enable it.
enable_operator_batch_size_stats	true	If this is true, enable the operator input/output batch size stats collection in driver execution. This can be expensive for data types with a large number of columns (e.g., ROW types) as it calls estimateFlatSize() which recursively calculates sizes for all child vectors.
unnest_split_output	true	If this is true, then the unnest operator might split output for each input batch based on the output batch size control. Otherwise, it produces a single output for each input batch.
query_memory_reclaimer_priority	2147483647	Priority of the query in the memory pool reclaimer. Lower value means higher priority. This is used in global arbitration victim selection.
max_num_splits_listened_to	0	The max number of input splits to listen to by SplitListener per table scan node per worker. It's up to the SplitListener implementation to respect this config.
source	(empty)	Source of the query. Used by Presto to identify the file system username.
client_tags	(empty)	Client tags of the query. Used by Presto to identify the file system username.
